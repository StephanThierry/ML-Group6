{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning</h1><h2 align=\"center\" style=\"margin:10px\">Assignment 3</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Group 6:\n",
    "    287040 Stephan Thierry\n",
    "    254172 Kasper Holst Daugaard \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignments below should be solved and documented as a mini-project that will form the basis for the\n",
    "examination. When solving the exercises it is important that you\n",
    "\n",
    "  * document all relevant results and analyses that you have obtained/performed during the exercises\n",
    "  * try to relate your results to the theoretical background of the methods being applied.\n",
    "\n",
    "Feel free to add cells if you need to. The easiest way to convert to pdf is to save this notebook as .html (File-->Download as-->HTML) and then convert this html file to pdf. You can also export as pdf directly, but here you need to watch your margins as the converter will cut off your code (i.e. make vertical code!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Linear vs nonlinear classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show a dataset that cannot be linearly separated. In this exercise, we will use the default parameters for all classifiers (except the custom SVM in exercise d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_circles\n",
    "X, y = make_circles(1000, factor=0.0, noise=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Plot the dataset e.g. using the `discrete_scatter`-function from mglearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(X[:,0],X[:,1], y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b) Split the dataset into train and test-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we could split using a random_state that demonstrates the outcome that we want to show (3). Other random_state's (4) will show a much lower accuracy - but knowing that data it should be about 50/50.\n",
    "\n",
    "Instead we stratify on y so the data is split evenly and there is not an overrepresentation of one classification in either of the new datasets\n",
    "\n",
    "We don't set \"test_size\" so we use the default split of 75/25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c) Train a logistic regression on the dataset, and compute the classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Logreg = LogisticRegression(solver='lbfgs')\n",
    "##Logreg.fit(X_train,y_train)\n",
    "Logreg.fit(X_train,y_train)\n",
    "print (Logreg.predict_proba([X_test[0]]))\n",
    "print (Logreg.predict_proba([X_test[10]]))\n",
    "print (Logreg.predict_proba([X_test[100]]))\n",
    "\n",
    "print(\"Accuracy on Training set is: {:.2f}\".format(Logreg.score(X_train,y_train)))\n",
    "print(\"Accuracy on Test set is: {:.2f}\".format(Logreg.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on the training set at test the accuracy on the test set. As expected it's around 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plot the decision boundary for the logistic regression (e.g. using the `plot_2d_separator`-function from mglearn), and use this to investigate why the algorithm does not give a good result in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logreg.fit(X_train,y_train)\n",
    "from mglearn.plots import plot_2d_separator\n",
    "mglearn.discrete_scatter(X_train[:,0],X_train[:,1], y_train)\n",
    "plt.plot(X_train[0,0],X_train[0,1],'k.')\n",
    "plt.legend()\n",
    "plot_2d_separator(Logreg, X_train, fill=True, eps=0.4, alpha=.7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the linier boundry in a 2d space will not accurately seperate the data. It's split down the middle so ~50/50 is the best we can hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e) Think of a feature you could add to this dataset to make it linearly separable. \n",
    "Add this feature, retrain the logistic regression classifier, and compute the accuracy again. Comment on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is a circle inside another circle, adding \"distance to the center\" as a feature would be useful to the liner (plane) seperation \n",
    "\n",
    "From using distance from scipy.spatial we calculate the euclidean distance to the center. The center is at 0,0 - but if it was not we could calculate is and change the center-variable accordingly\n",
    "\n",
    "See code comments for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add distance as new feature\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "center = [0,0];\n",
    "X2 = np.empty([0,3])\n",
    "\n",
    "#We run through each row of X and add the distance as a feature in each row\n",
    "for eachitem in X:\n",
    "    # Calculate distance to center\n",
    "    dist = distance.euclidean(center, eachitem)\n",
    "    # Add (insert) the distance to the current row and add (vertical-stack) the result to the resultset: X2 \n",
    "    X2 = np.vstack((X2,np.insert(eachitem, 2, dist)))\n",
    "\n",
    "## print(X2)\n",
    "\n",
    "# We do a new split so test and traing sets contain the new feature\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, stratify=y)\n",
    "\n",
    "## We use the X_plot and y_plot vaiables so we can run the plot-code on both \n",
    "##  the full dataset and the training-set by only changing 2 lines\n",
    "\n",
    "##X_plot = X2\n",
    "##y_plot = y\n",
    "\n",
    "X_plot = X2_train\n",
    "y_plot = y2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D, axes3d\n",
    "figure = plt.figure()\n",
    "# visualize in 3D\n",
    "ax = Axes3D(figure, elev=-152, azim=-26)\n",
    "# plot first all the points with y == 0, then all with y == 1\n",
    "mask = y_plot == 0\n",
    "ax.scatter(X_plot[mask, 0], X_plot[mask, 1], X_plot[mask, 2], c='b',\n",
    "    cmap=mglearn.cm2, s=60)\n",
    "ax.scatter(X_plot[~mask, 0], X_plot[~mask, 1], X_plot[~mask, 2], c='r', marker='^',\n",
    "    cmap=mglearn.cm2, s=60)\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Distance to center\")\n",
    "\n",
    "linear_3d = Logreg.fit(X_plot, y_plot)\n",
    "coef, intercept = linear_3d.coef_.ravel(), linear_3d.intercept_\n",
    "# show linear decision boundary\n",
    "figure = plt.figure()\n",
    "ax = Axes3D(figure, elev=-152, azim=-26)\n",
    "xx = np.linspace(X_plot[:, 0].min() - 2, X_plot[:, 0].max() + 2, 50)\n",
    "yy = np.linspace(X_plot[:, 1].min() - 2, X_plot[:, 1].max() + 2, 50)\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "ZZ = (coef[0] * XX + coef[1] * YY + intercept) / -coef[2]\n",
    "ax.plot_surface(XX, YY, ZZ, rstride=8, cstride=8, alpha=0.3)\n",
    "ax.scatter(X_plot[mask, 0], X_plot[mask, 1], X_plot[mask, 2], c='b',\n",
    "    cmap=mglearn.cm2, s=60)\n",
    "ax.scatter(X_plot[~mask, 0], X_plot[~mask, 1], X_plot[~mask, 2], c='r', marker='^',\n",
    "    cmap=mglearn.cm2, s=60)\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Distance to center\")\n",
    "\n",
    "print('Accuracy on training set: {:.2f}'.format(linear_3d.score(X2_train, y2_train)))\n",
    "print('Accuracy on test set: {:.2f}'.format(linear_3d.score(X2_test, y2_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "f) Now, return to the original dataset (without the extra feature), and train a kernelized SVM on the dataset. Compute the accuracy and plot the decision boundary. Compare to your previous results and discuss the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(gamma='auto').fit(X_train,y_train)\n",
    "\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "\n",
    "##fig, axes = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "plot_2d_separator(svm, X, fill=True, eps=0.5, alpha=.7 )\n",
    "##plt.figure(figsize=(20,20))\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svm.score(X_test, y_test)))\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernelized SVM does not rely on a liniear seperation of the data, so we don't need to move into a higher dimintion to achive accurate seperation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(25,20))\n",
    "\n",
    "for ax, C in zip(axes, [0.1, 1, 1000]):\n",
    "    for a, gamma in zip(ax,[0.1, 1, 10]):\n",
    "        svm = SVC(C=C, gamma=gamma).fit(X,y)\n",
    "        mglearn.discrete_scatter(X[:,0],X[:,1], y, ax=a)\n",
    "        mglearn.plots.plot_2d_separator(svm, X, eps=.5, fill=True, alpha=0.3, ax=a)\n",
    "        a.set_title(\"C={:.3f}, gamma={:.3f}\".format(C,gamma))\n",
    "        \n",
    "svm.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(axes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we consider the famous MNIST dataset, which is loaded below. The part of the dataset loaded as `testX` and `testY` will be reserved for testing - i.e. these cannot be used at all during training. \n",
    "\n",
    "It might be a good idea to only use part of the dataset (`X` and `Y`) while tuning parameters (in order to reduce the training-time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn.datasets.mnist as mnist\n",
    "X, Y, testX, testY = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code-snippet below can be used to see the digits corresponding to individual digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index = 1\n",
    "\n",
    "plt.imshow(X[index].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Split the training data into a training and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, Y, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) To begin with, in order to make things a little bit simpler (and faster!), extract from the data a binary subset, that only contains the data for two selected digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Take two digits 5 and 2\n",
    "\n",
    "reducedIndexes = np.isin(y, [2,5])\n",
    "X_subset, y_subset = X[reducedIndexes], y[reducedIndexes]\n",
    "\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_subset, y_subset, stratify=Y)\n",
    "\n",
    "print(y_train.size) # 41250 elements\n",
    "print(y_train_subset.size) # reduced to 7843 elements (if we dont use the \"break\")\n",
    "\n",
    "plt.imshow(X_train_subset[0].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Learn different SVM models by varying the kernel function. For each configuration,\n",
    "determine the time it takes to learn the model, and the accuracy on the validation data. *Caution*: for some\n",
    "configurations, learning here can take a little while (several minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It must be one of ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_subset, y_train_subset, stratify=y_train_subset)\n",
    "\n",
    "import mglearn\n",
    "import time\n",
    "numberList = [1, 2, 3]\n",
    "kernelList = [1, 2, 3, 4]\n",
    "\n",
    "for C in [0.1, 1, 1000]:\n",
    "    for gamma in [0.1, 1, 10]:\n",
    "        for kernel in ['poly','rbf','sigmoid']:\n",
    "            start = time.time()\n",
    "            svm = SVC(C=C, gamma=gamma, kernel=kernel).fit(X_train,y_train)\n",
    "            end = time.time()\n",
    "            #mglearn.discrete_scatter(X_train_subset[:,0],X_train_subset[:,1], y_train_subset, ax=a)\n",
    "            #mglearn.plots.plot_2d_separator(svm, X_train_subset, eps=.5, fill=True, alpha=0.3, ax=a)\n",
    "            #a.set_title(\"C={:.3f}, gamma={:.3f}\".format(C,1))\n",
    "            print(\"C: \" + str(C) + \" gamma: \" + str(gamma) + \" Kernel: \"+ kernel + \" Time: \" + str(end - start))\n",
    "            print(\"Accuracy on training subset: {:.2f}\".format(svm.score(X_train, y_train)))\n",
    "            print(\"Accuracy on test subset: {:.2f}\".format(svm.score(X_test, y_test)))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Find a way to extract the misclassified test cases. Inspect some misclassified cases and display them along with their correct label.\n",
    "Do they correspond to hard to recognize digits (also for the human reader)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=1, gamma=1, kernel='poly').fit(X_train,y_train)\n",
    "print(\"Accuracy on training subset: {:.2f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test subset: {:.2f}\".format(svm.score(X_test, y_test)))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "misclassified = np.where(y_test != svm.predict(X_test))\n",
    "misclassified = misclassified[0]\n",
    "predictions = svm.predict(X_test)\n",
    "for i in range(8):\n",
    "    print(\"Prediction: \"  + str(predictions[misclassified[i]]))\n",
    "    print(\"Actual: \" + str(y_test[misclassified[i]]))\n",
    "    \n",
    "    plt.imshow(X_test[misclassified[i]].reshape(28,28),cmap=plt.cm.gray_r)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How do results (time and accuracy) change, depending on whether you consider\n",
    "an 'easy' binary task (e.g. distinguishing '1' and '0') or a more difficult one (e.g. '4' vs. '5'). This exercise\n",
    "requires you to make new datasets with different values for 'digit1' and 'digit2'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) [Discussion only] Explain how a binary classifier, such as an SVM, can be applied to a multiclass classification problem, such as recognizing all 10 digits in the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) From the binary classification exercise above, identify a good configuration that gives a reasonable combination\n",
    "of accuracy and runtime. Use this configuration to perform a full classification of the 10 classes in the\n",
    "original dataset. Report the accuracy obtained on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Regression with random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will be using the famous nycflights dataset.\n",
    "\n",
    "So far, we have only considered how to use SVMs and decision trees (and, by extension, random forests) for classification. However, both algorithms can also be used for regression tasks, as we will see in the exercises below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "a) Load the data as a pandas dataframe and display the first 5 rows of the dataset. Remove the columns `'carrier'`,`'tailnum'`,`'flight'`,`'origin'`, and `'dest'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "flights= pd.read_csv('flights.csv')\n",
    "for col in ['carrier','tailnum','flight','origin','dest']:\n",
    "    flights = flights.drop(columns=col)\n",
    "print(\"Columns after drop: \" + str(flights.columns))\n",
    "\n",
    "# Display first 5 rows\n",
    "print(flights[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b) Plot the distributions for all variables (hint: use the `hist` method for the dataframe). Consider if you want to transform any of the variables, i.e. using a logarithmic transformation. Explain your choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike standard regression methods, decition trees do not rely on calculating coefficients so the requirements for data preparation are not the same as for SVM or other regression-type functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "flights.hist( figsize=(14,16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c) Handle any nan-values in the dataset, and normalize all relevant variables. Are there any categorical variables? If so, create dummy variables for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## This section is to detect \n",
    "\n",
    "print(\"Null values exist in the dataset (true or false) \" + str(flights.isnull().any().any()))\n",
    "print()\n",
    "print(\"In what features can we find null values: \")\n",
    "print(flights.isnull().any())\n",
    "print()\n",
    "print(\"How many?\")\n",
    "print(flights.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We have the option to delete entries with Null or to replace them with another value \n",
    "#  like the mean, the mode or the median - in this case we use the \n",
    "#  'mode' meaning the most frequent observation. The code for \"mean\" is included in the comment\n",
    "\n",
    "for col in ['dep_time','dep_delay','arr_time','arr_delay','air_time','hour','minute']:\n",
    "    flights[col] = flights[col].fillna(flights[col].mode()[0])\n",
    "    #flights[col] = flights[col].fillna(flights[col].mean())\n",
    "\n",
    "# We now see that we have 0 nulls in our dataset\n",
    "print(flights.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed the obvoius categorical fields 'carrier', 'tailnum','flight','origin' and 'dest' - year and month could be candidates since they are not quanties. However, it's not clear that it will improve the model to convert them. \n",
    "\n",
    "It could be done using below code:   \n",
    "`fight_withdummies = pd.get_dummies(flights, prefix='year_', columns=['year'])`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) In the following, we are going to determine which factors cause departure time delays, and try to predict the length of these delays. However, for several departures, a *negative* delay have been reported. How do you interpret a negative delay? Consider if you want to modify the negative delays in some way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative delay is most likely a flight that arrives ahead of schedule. Two approches could be used.   \n",
    "\n",
    "1. Consider the negative delays along side the delays - because if departures during rain are sometimes delayed and sometimes are ahead of schedule then it's not clear that rain is contributing to the delay. Whereas if you filter out the negatives incorrect patterns might emerge  \n",
    "\n",
    "2. We could also choose to only look at delays and disregard flights that are ahead, since being ahead of schedule has a very limited positive impact compared to the negative of being delayed\n",
    "\n",
    "We have chosen option 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression analysis: Predicting departure time delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Extract the features and the target variable (in this case the departure time delays) from the dataframe. Split the dataset into test and train sets (technically, we ought to have done this before preprocessing. For the sake of simplicity, we do not conform to this best practice in this exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = flights['dep_delay']\n",
    "\n",
    "# We drop dep_delay from the dataset since it's now our taget - and we also drop arr_delay since that will not be known \n",
    "#  at the time we are trying to prodict departure delay.\n",
    "\n",
    "# If we leave arr_delay in as a part of the dataset, prediction will be vastly improved - but that would not be \n",
    "#  representing a real-life senario\n",
    "\n",
    "X = flights.drop(columns='dep_delay').drop(columns='arr_delay')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Train a decision tree regressor for predicting departure time delays (you might want to experiment with a few different values of the hyperparameters to avoid too much overfitting). Plot the tree, and explain how decision trees can be used for regression analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# max_depth=9 is the tipping poing of where we only get an increased accuracy on \n",
    "#   the trainingset (overfitting) by increasing the value. If we lower the value we get a lower\n",
    "#   score on the test set (underfitting)\n",
    "tree = DecisionTreeRegressor(max_depth=9)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training data: {}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on testing data: {}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz as graphviz\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "dot_data = export_graphviz(tree, out_file=None,filled=True, rounded=True,special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Do a regression analysis as the one above, but using a random forest instead of a single decision tree. Use a grid-search to determine a good set of hyperparameters. When you have found the best model, score your model on the test set. Comment on the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# max_depth=9 - since it seemed to produce good results in the prev. example\n",
    "# max_features=5 - we want to find feature_importances_ so we reduce to a limited subset of our features\n",
    "\n",
    "RandForReg = RandomForestRegressor(max_depth=9, random_state=0, n_estimators=60, max_features=5)\n",
    "RandForReg.fit(X_train, y_train)\n",
    "\n",
    "#RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "#           max_features='auto', max_leaf_nodes=None,\n",
    "#           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#           min_samples_leaf=1, min_samples_split=2,\n",
    "#           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "print(RandForReg.score(X_test, y_test))\n",
    "# Acc: ~0.29, random forest is doing only slightly better (~0.03) than the standard DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RandForReg.feature_importances_)\n",
    "\n",
    "n_features = X_train.columns\n",
    "plt.barh(range(len(n_features)), RandForReg.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(n_features), n_features)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Plot the feature importances determined by the tree. Which feature is the most important? Do you have any idea as to why? Remove any features which cannot be used to predict departure time delays in any meaningful way, and redo the analysis. Comment on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression analysis: Predicting arrival time delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last part of the exercise, we are going to try to predict arrival time delays as a function of departure time delays - it might be of interest to know how large a delay one should expect after the plane has departed from the airport. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Train a decision tree or random forest regressor and an OLS (Ordinary least squares) to the dataset, and see how well arrival time delay. can be predicted based on departure time delay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "flights = pd.read_csv('flights.csv')\n",
    "\n",
    "# Set all null values to the mode - except in the target 'arr_delay'\n",
    "for col in ['dep_time','dep_delay','arr_time','air_time','hour','minute']:\n",
    "    flights[col] = flights[col].fillna(flights[col].mode()[0])    \n",
    "\n",
    "# Only the target column now contains Null - drop all rows that don't have a valid target    \n",
    "flights.dropna()\n",
    "\n",
    "# The training target y is now \"arr_delay\" \n",
    "y = flights['arr_delay']\n",
    "\n",
    "# We drop the taget \"arr_delay\" from the dataset and \"air_time\" since that is not known at the \n",
    "#  time we try to make the prediction\n",
    "flights = flights.drop(columns='arr_delay').drop(columns='air_time') \n",
    "\n",
    "# We make dummy colums for the category features and drop the original column afterwards\n",
    "for col in ['carrier','tailnum','flight','origin','dest']:\n",
    "    flights = pd.get_dummies(flights, prefix=col, columns=[col])\n",
    "    #flights = flights.drop(columns=col)\n",
    "\n",
    "\n",
    "# We split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(flights, y)\n",
    "# Laptop   - 2min30\n",
    "# i9-9900k - 26 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>carrier</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>flight</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>distance</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314904</th>\n",
       "      <td>314905</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>946.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N611QX</td>\n",
       "      <td>5463</td>\n",
       "      <td>LGA</td>\n",
       "      <td>BNA</td>\n",
       "      <td>764</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280779</th>\n",
       "      <td>280780</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N19966</td>\n",
       "      <td>3830</td>\n",
       "      <td>EWR</td>\n",
       "      <td>RIC</td>\n",
       "      <td>277</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71886</th>\n",
       "      <td>71887</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>N329AA</td>\n",
       "      <td>3</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2475</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23410</th>\n",
       "      <td>23411</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>627.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>US</td>\n",
       "      <td>N564UW</td>\n",
       "      <td>1507</td>\n",
       "      <td>EWR</td>\n",
       "      <td>CLT</td>\n",
       "      <td>529</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180538</th>\n",
       "      <td>180539</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>954.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>US</td>\n",
       "      <td>N751UW</td>\n",
       "      <td>1277</td>\n",
       "      <td>LGA</td>\n",
       "      <td>CLT</td>\n",
       "      <td>544</td>\n",
       "      <td>9.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302946</th>\n",
       "      <td>302947</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>905.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>MQ</td>\n",
       "      <td>N544MQ</td>\n",
       "      <td>3565</td>\n",
       "      <td>LGA</td>\n",
       "      <td>CLT</td>\n",
       "      <td>544</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59539</th>\n",
       "      <td>59540</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>655.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N643JB</td>\n",
       "      <td>3</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1598</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99152</th>\n",
       "      <td>99153</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N832AS</td>\n",
       "      <td>5736</td>\n",
       "      <td>LGA</td>\n",
       "      <td>IAD</td>\n",
       "      <td>229</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150958</th>\n",
       "      <td>150959</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1857.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N3738B</td>\n",
       "      <td>2159</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MCO</td>\n",
       "      <td>944</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71341</th>\n",
       "      <td>71342</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N508JB</td>\n",
       "      <td>161</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SMF</td>\n",
       "      <td>2521</td>\n",
       "      <td>19.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146574</th>\n",
       "      <td>146575</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>801.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N14116</td>\n",
       "      <td>4157</td>\n",
       "      <td>EWR</td>\n",
       "      <td>OMA</td>\n",
       "      <td>1134</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282634</th>\n",
       "      <td>282635</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N37470</td>\n",
       "      <td>195</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1608</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165358</th>\n",
       "      <td>165359</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>956.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N22909</td>\n",
       "      <td>4187</td>\n",
       "      <td>EWR</td>\n",
       "      <td>BNA</td>\n",
       "      <td>748</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286597</th>\n",
       "      <td>286598</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N712JB</td>\n",
       "      <td>623</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2475</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42772</th>\n",
       "      <td>42773</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2105.0</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8977A</td>\n",
       "      <td>3854</td>\n",
       "      <td>LGA</td>\n",
       "      <td>GSP</td>\n",
       "      <td>610</td>\n",
       "      <td>18.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74878</th>\n",
       "      <td>74879</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N539UA</td>\n",
       "      <td>394</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2565</td>\n",
       "      <td>12.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288453</th>\n",
       "      <td>288454</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>YV</td>\n",
       "      <td>N927LR</td>\n",
       "      <td>2751</td>\n",
       "      <td>LGA</td>\n",
       "      <td>CLT</td>\n",
       "      <td>544</td>\n",
       "      <td>20.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26601</th>\n",
       "      <td>26602</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N661DN</td>\n",
       "      <td>1773</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SLC</td>\n",
       "      <td>1990</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205303</th>\n",
       "      <td>205304</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2135.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N806JB</td>\n",
       "      <td>391</td>\n",
       "      <td>LGA</td>\n",
       "      <td>MCO</td>\n",
       "      <td>950</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278958</th>\n",
       "      <td>278959</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>653.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8506C</td>\n",
       "      <td>3879</td>\n",
       "      <td>EWR</td>\n",
       "      <td>CVG</td>\n",
       "      <td>569</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286872</th>\n",
       "      <td>286873</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>908.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N607LR</td>\n",
       "      <td>5222</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DTW</td>\n",
       "      <td>488</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35081</th>\n",
       "      <td>35082</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N829AS</td>\n",
       "      <td>5712</td>\n",
       "      <td>JFK</td>\n",
       "      <td>IAD</td>\n",
       "      <td>228</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151677</th>\n",
       "      <td>151678</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N594JB</td>\n",
       "      <td>36</td>\n",
       "      <td>JFK</td>\n",
       "      <td>ROC</td>\n",
       "      <td>264</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49809</th>\n",
       "      <td>49810</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>WN</td>\n",
       "      <td>N968WN</td>\n",
       "      <td>1341</td>\n",
       "      <td>LGA</td>\n",
       "      <td>BNA</td>\n",
       "      <td>764</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52260</th>\n",
       "      <td>52261</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>838.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N504UA</td>\n",
       "      <td>365</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SAN</td>\n",
       "      <td>2425</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252195</th>\n",
       "      <td>252196</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N740EV</td>\n",
       "      <td>5207</td>\n",
       "      <td>LGA</td>\n",
       "      <td>BGR</td>\n",
       "      <td>378</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253884</th>\n",
       "      <td>253885</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N415UA</td>\n",
       "      <td>349</td>\n",
       "      <td>EWR</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2454</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220590</th>\n",
       "      <td>220591</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>N579AA</td>\n",
       "      <td>327</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>733</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73721</th>\n",
       "      <td>73722</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>945.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N746JB</td>\n",
       "      <td>483</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MCO</td>\n",
       "      <td>944</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262083</th>\n",
       "      <td>262084</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N618JB</td>\n",
       "      <td>703</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1598</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41846</th>\n",
       "      <td>41847</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N815UA</td>\n",
       "      <td>208</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2402</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56015</th>\n",
       "      <td>56016</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>733.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N316JB</td>\n",
       "      <td>885</td>\n",
       "      <td>JFK</td>\n",
       "      <td>RDU</td>\n",
       "      <td>427</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220223</th>\n",
       "      <td>220224</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>2322.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N247JB</td>\n",
       "      <td>30</td>\n",
       "      <td>JFK</td>\n",
       "      <td>ROC</td>\n",
       "      <td>264</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221547</th>\n",
       "      <td>221548</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>MQ</td>\n",
       "      <td>N711MQ</td>\n",
       "      <td>4471</td>\n",
       "      <td>LGA</td>\n",
       "      <td>RDU</td>\n",
       "      <td>431</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115078</th>\n",
       "      <td>115079</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>WN</td>\n",
       "      <td>N250WN</td>\n",
       "      <td>1078</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PHX</td>\n",
       "      <td>2133</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274954</th>\n",
       "      <td>274955</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N707TW</td>\n",
       "      <td>1465</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2586</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15228</th>\n",
       "      <td>15229</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>VX</td>\n",
       "      <td>N842VA</td>\n",
       "      <td>23</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2586</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196818</th>\n",
       "      <td>196819</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>N482AA</td>\n",
       "      <td>2019</td>\n",
       "      <td>LGA</td>\n",
       "      <td>STL</td>\n",
       "      <td>888</td>\n",
       "      <td>15.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319183</th>\n",
       "      <td>319184</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>708</td>\n",
       "      <td>EWR</td>\n",
       "      <td>ORD</td>\n",
       "      <td>719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212097</th>\n",
       "      <td>212098</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>714.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>VX</td>\n",
       "      <td>N623VA</td>\n",
       "      <td>399</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2475</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72371</th>\n",
       "      <td>72372</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N355JB</td>\n",
       "      <td>418</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BOS</td>\n",
       "      <td>187</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287044</th>\n",
       "      <td>287045</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>N618AA</td>\n",
       "      <td>2041</td>\n",
       "      <td>JFK</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1089</td>\n",
       "      <td>12.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62207</th>\n",
       "      <td>62208</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2213.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>N966AT</td>\n",
       "      <td>1346</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>762</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211321</th>\n",
       "      <td>211322</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N37413</td>\n",
       "      <td>1120</td>\n",
       "      <td>EWR</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2565</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200960</th>\n",
       "      <td>200961</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>640.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N37420</td>\n",
       "      <td>1686</td>\n",
       "      <td>EWR</td>\n",
       "      <td>BOS</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92238</th>\n",
       "      <td>92239</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>MQ</td>\n",
       "      <td>N506MQ</td>\n",
       "      <td>3473</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>762</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180104</th>\n",
       "      <td>180105</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N38458</td>\n",
       "      <td>1247</td>\n",
       "      <td>EWR</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2454</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134952</th>\n",
       "      <td>134953</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>VX</td>\n",
       "      <td>N633VA</td>\n",
       "      <td>413</td>\n",
       "      <td>JFK</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2475</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58227</th>\n",
       "      <td>58228</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N648JB</td>\n",
       "      <td>135</td>\n",
       "      <td>JFK</td>\n",
       "      <td>PHX</td>\n",
       "      <td>2153</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128375</th>\n",
       "      <td>128376</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>9E</td>\n",
       "      <td>N8458A</td>\n",
       "      <td>3638</td>\n",
       "      <td>JFK</td>\n",
       "      <td>PHL</td>\n",
       "      <td>94</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175978</th>\n",
       "      <td>175979</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N13988</td>\n",
       "      <td>4269</td>\n",
       "      <td>EWR</td>\n",
       "      <td>IAD</td>\n",
       "      <td>212</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115945</th>\n",
       "      <td>115946</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>UA</td>\n",
       "      <td>N481UA</td>\n",
       "      <td>743</td>\n",
       "      <td>LGA</td>\n",
       "      <td>IAH</td>\n",
       "      <td>1416</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232027</th>\n",
       "      <td>232028</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1630.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N364NW</td>\n",
       "      <td>2231</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DTW</td>\n",
       "      <td>502</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289327</th>\n",
       "      <td>289328</td>\n",
       "      <td>2013</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N569JB</td>\n",
       "      <td>225</td>\n",
       "      <td>JFK</td>\n",
       "      <td>TPA</td>\n",
       "      <td>1005</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39922</th>\n",
       "      <td>39923</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>N316US</td>\n",
       "      <td>2307</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SAT</td>\n",
       "      <td>1587</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127222</th>\n",
       "      <td>127223</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>851.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N568JB</td>\n",
       "      <td>517</td>\n",
       "      <td>EWR</td>\n",
       "      <td>MCO</td>\n",
       "      <td>937</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111332</th>\n",
       "      <td>111333</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>618.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>EV</td>\n",
       "      <td>N13202</td>\n",
       "      <td>4708</td>\n",
       "      <td>EWR</td>\n",
       "      <td>MKE</td>\n",
       "      <td>725</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108601</th>\n",
       "      <td>108602</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>N974AT</td>\n",
       "      <td>1182</td>\n",
       "      <td>LGA</td>\n",
       "      <td>CAK</td>\n",
       "      <td>397</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119334</th>\n",
       "      <td>119335</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>B6</td>\n",
       "      <td>N509JB</td>\n",
       "      <td>505</td>\n",
       "      <td>EWR</td>\n",
       "      <td>FLL</td>\n",
       "      <td>1065</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183564</th>\n",
       "      <td>183565</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>N954AT</td>\n",
       "      <td>348</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>762</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252582 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  year  month  day  dep_time  dep_delay  arr_time carrier  \\\n",
       "314904      314905  2013      9    7     946.0       -4.0    1059.0      EV   \n",
       "280779      280780  2013      8    1    2227.0       88.0    2355.0      EV   \n",
       "71886        71887  2013     11   18    1219.0       19.0    1514.0      AA   \n",
       "23410        23411  2013      1   28     627.0       -3.0     815.0      US   \n",
       "180538      180539  2013      4   17     954.0       -5.0    1212.0      US   \n",
       "302946      302947  2013      8   25     905.0      -10.0    1039.0      MQ   \n",
       "59539        59540  2013     11    5     655.0      -10.0    1125.0      B6   \n",
       "99152        99153  2013     12   18    1012.0        6.0    1204.0      EV   \n",
       "150958      150959  2013      3   16    1857.0        0.0    2136.0      DL   \n",
       "71341        71342  2013     11   17    1954.0       22.0    2339.0      B6   \n",
       "146574      146575  2013      3   12     801.0       -3.0    1007.0      EV   \n",
       "282634      282635  2013      8    3    2111.0       19.0      54.0      UA   \n",
       "165358      165359  2013      4    1     956.0       -5.0    1127.0      EV   \n",
       "286597      286598  2013      8    7    2319.0       34.0     254.0      B6   \n",
       "42772        42773  2013     10   17    1854.0       -6.0    2105.0      9E   \n",
       "74878        74879  2013     11   21    1258.0        9.0    1619.0      UA   \n",
       "288453      288454  2013      8    9    2059.0      204.0    2253.0      YV   \n",
       "26601        26602  2013      1   31    1611.0       21.0    1937.0      DL   \n",
       "205303      205304  2013      5   13    1908.0       69.0    2135.0      B6   \n",
       "278958      278959  2013      7   31     653.0       -7.0     904.0      9E   \n",
       "286872      286873  2013      8    8     908.0       -2.0    1113.0      EV   \n",
       "35081        35082  2013     10    9    1532.0       78.0    1649.0      EV   \n",
       "151677      151678  2013      3   17    1701.0       -2.0    1809.0      B6   \n",
       "49809        49810  2013     10   25    1057.0       -3.0    1232.0      WN   \n",
       "52260        52261  2013     10   28     838.0       -7.0    1145.0      UA   \n",
       "252195      252196  2013      7    2    1906.0       41.0    2025.0      EV   \n",
       "253884      253885  2013      7    4    1646.0       -9.0    1900.0      UA   \n",
       "220590      220591  2013      5   30    1118.0       -7.0    1235.0      AA   \n",
       "73721        73722  2013     11   20     945.0       -4.0    1232.0      B6   \n",
       "262083      262084  2013      7   13    1429.0        0.0    1817.0      B6   \n",
       "...            ...   ...    ...  ...       ...        ...       ...     ...   \n",
       "41846        41847  2013     10   16    1933.0       -2.0    2214.0      UA   \n",
       "56015        56016  2013     11    1     733.0       -3.0    1146.0      B6   \n",
       "220223      220224  2013      5   29    2322.0       37.0      33.0      B6   \n",
       "221547      221548  2013      5   31    1052.0       -8.0    1220.0      MQ   \n",
       "115078      115079  2013      2    5    1331.0        1.0    1646.0      WN   \n",
       "274954      274955  2013      7   26    1907.0        7.0    2249.0      DL   \n",
       "15228        15229  2013      1   18    1035.0        5.0    1354.0      VX   \n",
       "196818      196819  2013      5    4    1552.0       -8.0    1703.0      AA   \n",
       "319183      319184  2013      9   11       NaN        NaN       NaN      UA   \n",
       "212097      212098  2013      5   21     714.0       14.0    1012.0      VX   \n",
       "72371        72372  2013     11   18    2005.0      -10.0    2151.0      B6   \n",
       "287044      287045  2013      8    8    1247.0        2.0    1547.0      AA   \n",
       "62207        62208  2013     11    7    1933.0       -2.0    2213.0      FL   \n",
       "211321      211322  2013      5   20    1030.0        0.0    1329.0      UA   \n",
       "200960      200961  2013      5    9     640.0       16.0     741.0      UA   \n",
       "92238        92239  2013     12   10    2101.0        2.0    2340.0      MQ   \n",
       "180104      180105  2013      4   16    1949.0       -9.0    2312.0      UA   \n",
       "134952      134953  2013      2   27    1722.0       27.0    2019.0      VX   \n",
       "58227        58228  2013     11    3    1736.0       -4.0    2102.0      B6   \n",
       "128375      128376  2013      2   20    1309.0        9.0    1356.0      9E   \n",
       "175978      175979  2013      4   12    1208.0       98.0    1321.0      EV   \n",
       "115945      115946  2013      2    6    1252.0        1.0    1606.0      UA   \n",
       "232027      232028  2013      6   11    1630.0        5.0    1842.0      DL   \n",
       "289327      289328  2013      8   10    1938.0        6.0    2226.0      B6   \n",
       "39922        39923  2013     10   14    2004.0       39.0    2300.0      DL   \n",
       "127222      127223  2013      2   19     851.0       16.0    1146.0      B6   \n",
       "111332      111333  2013      2    1     618.0       17.0     727.0      EV   \n",
       "108601      108602  2013     12   28    2036.0        3.0    2149.0      FL   \n",
       "119334      119335  2013      2   10    1336.0       16.0    1618.0      B6   \n",
       "183564      183565  2013      4   20    1315.0        0.0    1535.0      FL   \n",
       "\n",
       "       tailnum  flight origin dest  distance  hour  minute  \n",
       "314904  N611QX    5463    LGA  BNA       764   9.0    46.0  \n",
       "280779  N19966    3830    EWR  RIC       277  22.0    27.0  \n",
       "71886   N329AA       3    JFK  LAX      2475  12.0    19.0  \n",
       "23410   N564UW    1507    EWR  CLT       529   6.0    27.0  \n",
       "180538  N751UW    1277    LGA  CLT       544   9.0    54.0  \n",
       "302946  N544MQ    3565    LGA  CLT       544   9.0     5.0  \n",
       "59539   N643JB       3    JFK  SJU      1598   6.0    55.0  \n",
       "99152   N832AS    5736    LGA  IAD       229  10.0    12.0  \n",
       "150958  N3738B    2159    JFK  MCO       944  18.0    57.0  \n",
       "71341   N508JB     161    JFK  SMF      2521  19.0    54.0  \n",
       "146574  N14116    4157    EWR  OMA      1134   8.0     1.0  \n",
       "282634  N37470     195    EWR  SJU      1608  21.0    11.0  \n",
       "165358  N22909    4187    EWR  BNA       748   9.0    56.0  \n",
       "286597  N712JB     623    JFK  LAX      2475  23.0    19.0  \n",
       "42772   N8977A    3854    LGA  GSP       610  18.0    54.0  \n",
       "74878   N539UA     394    EWR  SFO      2565  12.0    58.0  \n",
       "288453  N927LR    2751    LGA  CLT       544  20.0    59.0  \n",
       "26601   N661DN    1773    JFK  SLC      1990  16.0    11.0  \n",
       "205303  N806JB     391    LGA  MCO       950  19.0     8.0  \n",
       "278958  N8506C    3879    EWR  CVG       569   6.0    53.0  \n",
       "286872  N607LR    5222    EWR  DTW       488   9.0     8.0  \n",
       "35081   N829AS    5712    JFK  IAD       228  15.0    32.0  \n",
       "151677  N594JB      36    JFK  ROC       264  17.0     1.0  \n",
       "49809   N968WN    1341    LGA  BNA       764  10.0    57.0  \n",
       "52260   N504UA     365    EWR  SAN      2425   8.0    38.0  \n",
       "252195  N740EV    5207    LGA  BGR       378  19.0     6.0  \n",
       "253884  N415UA     349    EWR  LAX      2454  16.0    46.0  \n",
       "220590  N579AA     327    LGA  ORD       733  11.0    18.0  \n",
       "73721   N746JB     483    JFK  MCO       944   9.0    45.0  \n",
       "262083  N618JB     703    JFK  SJU      1598  14.0    29.0  \n",
       "...        ...     ...    ...  ...       ...   ...     ...  \n",
       "41846   N815UA     208    EWR  SEA      2402  19.0    33.0  \n",
       "56015   N316JB     885    JFK  RDU       427   7.0    33.0  \n",
       "220223  N247JB      30    JFK  ROC       264  23.0    22.0  \n",
       "221547  N711MQ    4471    LGA  RDU       431  10.0    52.0  \n",
       "115078  N250WN    1078    EWR  PHX      2133  13.0    31.0  \n",
       "274954  N707TW    1465    JFK  SFO      2586  19.0     7.0  \n",
       "15228   N842VA      23    JFK  SFO      2586  10.0    35.0  \n",
       "196818  N482AA    2019    LGA  STL       888  15.0    52.0  \n",
       "319183     NaN     708    EWR  ORD       719   NaN     NaN  \n",
       "212097  N623VA     399    JFK  LAX      2475   7.0    14.0  \n",
       "72371   N355JB     418    JFK  BOS       187  20.0     5.0  \n",
       "287044  N618AA    2041    JFK  MIA      1089  12.0    47.0  \n",
       "62207   N966AT    1346    LGA  ATL       762  19.0    33.0  \n",
       "211321  N37413    1120    EWR  SFO      2565  10.0    30.0  \n",
       "200960  N37420    1686    EWR  BOS       200   6.0    40.0  \n",
       "92238   N506MQ    3473    LGA  ATL       762  21.0     1.0  \n",
       "180104  N38458    1247    EWR  LAX      2454  19.0    49.0  \n",
       "134952  N633VA     413    JFK  LAX      2475  17.0    22.0  \n",
       "58227   N648JB     135    JFK  PHX      2153  17.0    36.0  \n",
       "128375  N8458A    3638    JFK  PHL        94  13.0     9.0  \n",
       "175978  N13988    4269    EWR  IAD       212  12.0     8.0  \n",
       "115945  N481UA     743    LGA  IAH      1416  12.0    52.0  \n",
       "232027  N364NW    2231    LGA  DTW       502  16.0    30.0  \n",
       "289327  N569JB     225    JFK  TPA      1005  19.0    38.0  \n",
       "39922   N316US    2307    JFK  SAT      1587  20.0     4.0  \n",
       "127222  N568JB     517    EWR  MCO       937   8.0    51.0  \n",
       "111332  N13202    4708    EWR  MKE       725   6.0    18.0  \n",
       "108601  N974AT    1182    LGA  CAK       397  20.0    36.0  \n",
       "119334  N509JB     505    EWR  FLL      1065  13.0    36.0  \n",
       "183564  N954AT     348    LGA  ATL       762  13.0    15.0  \n",
       "\n",
       "[252582 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(flights.isnull().sum())\n",
    "#print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandForReg = RandomForestRegressor(max_depth=9, random_state=0, n_estimators=60, max_features=5)\n",
    "RandForReg.fit(X_train, y_train)\n",
    "\n",
    "print(RandForReg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Plot the arrival time delays as a function of the departure time delay, and show the predictions from each of the two regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Based on the results obtained above, make a plot that extrapolates a little bit in order to predict delays slightly larger than the largest delay found in the dataset. Which model do you think gives the most trustworthy extrapolation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Hopefully you found that it is possible to predict arrival time delays quite confidently from departure time delays. See if you can improve these predictions by including some (or all) of the other features. You are encouraged to try out several different machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
